<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-04-17T05:43:16.555Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>水论文的必要步骤1之期刊选择</title>
    <link href="http://example.com/2021/04/17/%E6%B0%B4%E8%AE%BA%E6%96%87%E7%9A%84%E5%BF%85%E8%A6%81%E6%AD%A5%E9%AA%A41%E4%B9%8B%E6%9C%9F%E5%88%8A%E9%80%89%E6%8B%A9/"/>
    <id>http://example.com/2021/04/17/%E6%B0%B4%E8%AE%BA%E6%96%87%E7%9A%84%E5%BF%85%E8%A6%81%E6%AD%A5%E9%AA%A41%E4%B9%8B%E6%9C%9F%E5%88%8A%E9%80%89%E6%8B%A9/</id>
    <published>2021-04-17T05:36:55.000Z</published>
    <updated>2021-04-17T05:43:16.555Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-概述"><a href="#0-概述" class="headerlink" title="0.概述"></a>0.概述</h1><p>这个水论文系列仅仅是对于论文写作的方法的总结，至于，写论文之前的数据、实验等因为各自的方向不同就不进行记录了。</p><p>这是第一篇，就是期刊选择，首先，假设，你已经有了一个方向和idea，然后准备开始水自己的第一篇论文了，那么不如看一看。</p><p>我们首先需要确定哪一个期刊包含自己所研究的方向，这里使用了小木虫，以自然语言处理方向为例。</p><p>首先，进入小木虫，<a href="http://muchong.com/">http://muchong.com/</a></p><p>然后点击期刊，下面会有期刊方向，写‘自然语言’，然后搜索，就会发现自然语言理解与机器翻译这个方向，那么下面的就是和你研究的方向相关的期刊。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;0-概述&quot;&gt;&lt;a href=&quot;#0-概述&quot; class=&quot;headerlink&quot; title=&quot;0.概述&quot;&gt;&lt;/a&gt;0.概述&lt;/h1&gt;&lt;p&gt;这个水论文系列仅仅是对于论文写作的方法的总结，至于，写论文之前的数据、实验等因为各自的方向不同就不进行记录了。&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    
    <category term="论文" scheme="http://example.com/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>整理-Git使用教程</title>
    <link href="http://example.com/2021/03/03/%E6%95%B4%E7%90%86-Git%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <id>http://example.com/2021/03/03/%E6%95%B4%E7%90%86-Git%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</id>
    <published>2021-03-03T10:51:56.000Z</published>
    <updated>2021-03-11T07:43:38.721Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-概述"><a href="#0-概述" class="headerlink" title="0.概述"></a>0.概述</h1><p>环境:Ubuntu</p><p>这里是关于Git使用的整理，将之前使用的相关的资料整理。包含下面的内容：</p><ol><li><p>SSH连接到Git(你不会想每次连接到Git的时候都输入账户名和密码的)<br>官方资料参考:<a href="https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh">https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh</a></p></li><li><p>建立本地仓库之后并上传到Github</p></li></ol><h1 id="1-内容"><a href="#1-内容" class="headerlink" title="1.内容"></a>1.内容</h1><h2 id="1-1-SSH连接到Git"><a href="#1-1-SSH连接到Git" class="headerlink" title="1.1 SSH连接到Git"></a>1.1 SSH连接到Git</h2><p>当你使用Git的时候，你会需要建立自己的仓库，时不时地对仓库进行操作更新等。每次都输入用户名和密码是非人类的，所以需要通过使用SSH连接到Git,这样就能够直接进行操作了。</p><p>参考资料在概述中有，下面我会详细讲述一下。</p><h3 id="1-1-1-关于SSH"><a href="#1-1-1-关于SSH" class="headerlink" title="1.1.1 关于SSH"></a>1.1.1 关于SSH</h3><p>使用SSH协议，您可以连接到远程服务器和服务并进行身份验证。使用SSH密钥，您可以连接到GitHub，而无需在每次访问时都提供用户名和个人访问令牌。</p><p>设置SSH时，您将生成一个SSH密钥并将其添加到ssh-agent中，然后将该密钥添加到您的GitHub帐户中。将SSH密钥添加到ssh-agent可以确保您的SSH密钥通过使用密码短语具有额外的安全性。</p><p>可以在用户中设置SSH Key，作为全局的SSH，或者对单个仓库设置SSH Key,来单独使用。</p><p>官方文档建议您定期查看SSH密钥列表，并撤消所有无效或已被破坏的密钥。</p><p>如果一年未使用SSH密钥，那么GitHub将自动删除非活动SSH密钥，以确保安全。</p><h3 id="1-1-2-检查现有的SSH密钥"><a href="#1-1-2-检查现有的SSH密钥" class="headerlink" title="1.1.2 检查现有的SSH密钥"></a>1.1.2 检查现有的SSH密钥</h3><p>在生成SSH密钥之前，您可以检查是否有任何现有的SSH密钥。</p><p>默认ssh key保存路径为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/.ssh</span><br></pre></td></tr></table></figure><p>如果已经有一个公共的SSH Key,那么文件中包含类似于下面的文件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">id_rsa</span><br><span class="line">id_rsa.pub</span><br><span class="line">known_hosts</span><br></pre></td></tr></table></figure><p>如果没有的话，可以到下面一步生成新的SSH Key，如果已经有了公钥和私钥对，那么就将跳跃到SSH Key添加到ssh-agent中去。</p><h3 id="1-1-3-生成新的SSH密钥并且添加到ssh-agent中"><a href="#1-1-3-生成新的SSH密钥并且添加到ssh-agent中" class="headerlink" title="1.1.3 生成新的SSH密钥并且添加到ssh-agent中"></a>1.1.3 生成新的SSH密钥并且添加到ssh-agent中</h3><p>这里其实是两步，针对上面是否有公钥和私钥对。</p><h4 id="1-1-3-1-生成新的SSH密钥"><a href="#1-1-3-1-生成新的SSH密钥" class="headerlink" title="1.1.3.1 生成新的SSH密钥"></a>1.1.3.1 生成新的SSH密钥</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t ed25519 -C <span class="string">&quot;your_email@example.com&quot;</span></span><br></pre></td></tr></table></figure><p>如果，你的系统不支持Ed25519，那么使用下面的内容:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C <span class="string">&quot;your_email@example.com&quot;</span></span><br></pre></td></tr></table></figure><h4 id="1-1-3-2-将SSH密钥添加到ssh-agent"><a href="#1-1-3-2-将SSH密钥添加到ssh-agent" class="headerlink" title="1.1.3.2 将SSH密钥添加到ssh-agent"></a>1.1.3.2 将SSH密钥添加到ssh-agent</h4><p>后台启动ssh-agent</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(ssh-agent -s)</span>&quot;</span></span><br></pre></td></tr></table></figure><p>将SSH私钥添加到ssh-agent,如果密钥是其他名称就使用其他名称，顺便说一下，私钥的路径上面说过了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/.ssh</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-add ~/.ssh/id_ed25519</span><br></pre></td></tr></table></figure><h3 id="1-1-4-向Github账户中添加SSH密钥"><a href="#1-1-4-向Github账户中添加SSH密钥" class="headerlink" title="1.1.4 向Github账户中添加SSH密钥"></a>1.1.4 向Github账户中添加SSH密钥</h3><p>要将GitHub帐户配置为使用新的（或现有的）SSH密钥，您还需要将其添加到GitHub帐户中。</p><p>打开xxx.pub，也就是公钥，然后将它复制。</p><p>到github页面右上角的个人资料，点击settings，在左边的栏目中点击SSH and GPG keys,点击New SSH key。</p><p>在title中，添加一个描述性的文字，例如”mytitle”<br>将公钥粘贴到Key中，是以ssh-xxx开始的内容</p><h3 id="1-1-5-测试SSH连接"><a href="#1-1-5-测试SSH连接" class="headerlink" title="1.1.5 测试SSH连接"></a>1.1.5 测试SSH连接</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>当第一次输入的时候会有如下的输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; The authenticity of host <span class="string">&#x27;github.com (IP ADDRESS)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">&gt; RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.</span></span><br><span class="line"><span class="string">&gt; Are you sure you want to continue connecting (yes/no)?</span></span><br></pre></td></tr></table></figure><p>确定之后，会有如下的输出:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; Hi username! You<span class="string">&#x27;ve successfully authenticated, but GitHub does not</span></span><br><span class="line"><span class="string">&gt; provide shell access.</span></span><br></pre></td></tr></table></figure><h3 id="1-1-5-备注"><a href="#1-1-5-备注" class="headerlink" title="1.1.5 备注"></a>1.1.5 备注</h3><p>记住我们使用的是SSH，所以当你使用HTTP连接的时候依然需要输入用户名和密码。只要选择SSH连接。。</p><h2 id="1-2-建立本地仓库后上传到Github"><a href="#1-2-建立本地仓库后上传到Github" class="headerlink" title="1.2 建立本地仓库后上传到Github"></a>1.2 建立本地仓库后上传到Github</h2><p>现在可以开始正式一些的项目了。</p><h3 id="1-2-1-创建一个本地仓库"><a href="#1-2-1-创建一个本地仓库" class="headerlink" title="1.2.1 创建一个本地仓库"></a>1.2.1 创建一个本地仓库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init MyProject</span><br></pre></td></tr></table></figure><p>会建立MyProject文件夹，然后文件夹中会有.git隐藏文件夹，其中包含的内容是一些索引、忽略的文件等配置。</p><h4 id="1-2-1-1-创建描述性文件"><a href="#1-2-1-1-创建描述性文件" class="headerlink" title="1.2.1.1 创建描述性文件"></a>1.2.1.1 创建描述性文件</h4><p>进入项目文件夹，然后建立描述文件README.md。这很重要！！！虽然没有这个文件也可以继续，但是强烈建议</p><h4 id="1-2-1-2-将文件添加到索引中"><a href="#1-2-1-2-将文件添加到索引中" class="headerlink" title="1.2.1.2 将文件添加到索引中"></a>1.2.1.2 将文件添加到索引中</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add filename</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">git add --all</span><br></pre></td></tr></table></figure><p>上面的是添加单个文件进入索引，下面是添加所有文件进入索引。</p><h4 id="1-2-1-3-提交对索引的更改"><a href="#1-2-1-3-提交对索引的更改" class="headerlink" title="1.2.1.3 提交对索引的更改"></a>1.2.1.3 提交对索引的更改</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -c <span class="string">&quot;comment&quot;</span></span><br></pre></td></tr></table></figure><p>后面是对于修改的一些注释，提交对索引的更改</p><h3 id="1-2-2-在Github上创建远端仓库"><a href="#1-2-2-在Github上创建远端仓库" class="headerlink" title="1.2.2 在Github上创建远端仓库"></a>1.2.2 在Github上创建远端仓库</h3><p>打开github.com，然后建立一个Repository,点点点。<br>创建完成之后，我们将本地仓库和Github上的仓库进行连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin https://github.com/user_name/Mytest.git</span><br></pre></td></tr></table></figure><p>后面的可以在网页上找到</p><h3 id="1-2-3-将本地仓库推送到Github远端仓库"><a href="#1-2-3-将本地仓库推送到Github远端仓库" class="headerlink" title="1.2.3 将本地仓库推送到Github远端仓库"></a>1.2.3 将本地仓库推送到Github远端仓库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push --set-upstream origin master</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;0-概述&quot;&gt;&lt;a href=&quot;#0-概述&quot; class=&quot;headerlink&quot; title=&quot;0.概述&quot;&gt;&lt;/a&gt;0.概述&lt;/h1&gt;&lt;p&gt;环境:Ubuntu&lt;/p&gt;
&lt;p&gt;这里是关于Git使用的整理，将之前使用的相关的资料整理。包含下面的内容：&lt;/p&gt;
&lt;ol&gt;</summary>
      
    
    
    
    
    <category term="git" scheme="http://example.com/tags/git/"/>
    
    <category term="ubuntu" scheme="http://example.com/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="http://example.com/2021/03/03/test-1/"/>
    <id>http://example.com/2021/03/03/test-1/</id>
    <published>2021-03-03T10:32:25.000Z</published>
    <updated>2021-03-03T10:33:42.732Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个新的test文件，因为git出现了新的问题。。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这是一个新的test文件，因为git出现了新的问题。。&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>关于残差网络的讨论</title>
    <link href="http://example.com/2021/02/08/%E5%85%B3%E4%BA%8E%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A8%E8%AE%BA/"/>
    <id>http://example.com/2021/02/08/%E5%85%B3%E4%BA%8E%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A8%E8%AE%BA/</id>
    <published>2021-02-08T07:53:05.000Z</published>
    <updated>2021-02-08T07:53:50.868Z</updated>
    
    <content type="html"><![CDATA[<p>参考：<br><a href="https://zhuanlan.zhihu.com/p/80226180">https://zhuanlan.zhihu.com/p/80226180</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考：&lt;br&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80226180&quot;&gt;https://zhuanlan.zhihu.com/p/80226180&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>基于图的文档级关系抽取</title>
    <link href="http://example.com/2021/02/07/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%96%87%E6%A1%A3%E7%BA%A7%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/"/>
    <id>http://example.com/2021/02/07/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%96%87%E6%A1%A3%E7%BA%A7%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/</id>
    <published>2021-02-07T11:02:59.000Z</published>
    <updated>2021-02-09T12:37:36.254Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h1><p>文档级关系抽取中的实体对通常贯穿于文档的多个句子中，和句子级的关系抽取相比需要更多的信息。</p><p>文档级关系抽取任务描述：<br>输入：实体1、实体2和文档<br>输出：两个实体之间的关系</p><p>为此，需要设计新的模型来获取更多的信息。为此，有了下面的方法。<br>(1) GCNN (Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network)<br>(2) EoG (Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs)<br>(3) GAIN (Double Graph Based Reasoning for Document-level Relation Extraction)(Graph Aggregation-and-Inference Network)</p><h1 id="2-模型"><a href="#2-模型" class="headerlink" title="2.模型"></a>2.模型</h1><h2 id="2-1-GCNN"><a href="#2-1-GCNN" class="headerlink" title="2.1 GCNN"></a>2.1 GCNN</h2><p>使用了GCNN网络，和普通的GCN类似，但是结构有所不同。</p><h3 id="2-1-1-结构"><a href="#2-1-1-结构" class="headerlink" title="2.1.1 结构"></a>2.1.1 结构</h3><p>节点： 文档中的word包含<br>(1) word的词向量<br>(2) word与目标实体的相对位置<br>![GCNN_example.png]</p><p>连线：关系<br>(1) Syntactic dependency edge:句法依赖<br>(2) Coreference edge:指代<br>(3) Adjacent sentence edge:相邻的上下句<br>(4) Adjacent word edge:相邻的上下word<br>(5) self node edge:自身</p><h3 id="2-1-2-算法"><a href="#2-1-2-算法" class="headerlink" title="2.1.2 算法"></a>2.1.2 算法</h3><p>对每一种关系图进行GCN的运算，然后将不同类型的关系图进行加权相加之后得到最后的结果。</p><p>最后使用了两个不同的全连接层，分别对应前一个和后一个实体。</p><p>![GCNN.png]</p><h2 id="2-2-EoG"><a href="#2-2-EoG" class="headerlink" title="2.2 EoG"></a>2.2 EoG</h2><p>使用了边的图，而不是基于节点。与之前的模型不同。这个模型有如下的特点。<br>(1) 包含实体的mentions对实体之间的关系很重要<br>(2) 实体对中实体的关系可以通过节点间的路径来表示，而不是基于节点</p><h3 id="2-2-1-结构"><a href="#2-2-1-结构" class="headerlink" title="2.2.1 结构"></a>2.2.1 结构</h3><p>节点：<br>(1)Mention node<br>与实体相关的mention的word embedding的平均<br>(2)Entity node<br>该实体的所有mention node的平均<br>(3)Sentence node<br>句子中的word embedding平均</p><p>连线： M,E,S:Mention,Entity,Sentence<br>(1)MM 同一个Sentence中的两个mention<br>(2)ME<br>(3)MS<br>(4)ES<br>(5)SS</p><p>![EoG.png]</p><h3 id="2-2-2-算法"><a href="#2-2-2-算法" class="headerlink" title="2.2.2 算法"></a>2.2.2 算法</h3><p>进行EoG算法，然后得到实体到实体的边的表示：<br>(1) 两个实体节点，选择其中的一个节点作为中间节点，然后，该路径的两条边通过神经网络，然后得到了这条路径的表示。<br>(2) 如果在实体之间已经存在了路径的表示，那么，将所有的路径与通过路径的两条边进行混合<br>(3) 将上面的步骤进行多次，就得到了混合后的实体到实体的边表示</p><p>最后，通过它进行分类。</p><h2 id="2-3-GAIN"><a href="#2-3-GAIN" class="headerlink" title="2.3 GAIN"></a>2.3 GAIN</h2><p>GAIN图聚合推理网络继承了EoG模型，三个问题:<br>(1) 同一个关系的主和宾可能位于不同的句子里面，无法通过一个句子来得到关系<br>(2) 同一个实体可能出现在不同的句子里面就，所以需要句子间的信息来表示实体<br>(3) 有的关系需要逻辑推理<br>得到了新的GAIN模型</p><p>这个模型包含两个图结构：<br>(1) hMG (heterogeneous mention-level graph)异构mention级别图<br>针对文档中不同mentions之间的互相关系</p><p>node：mention node 和 document node<br>(1) mention node 表示每一个mention<br>(2) document node 虚拟节点，对document信息，中继节点，有利于交互<br>edge:intra-entity edge,inter-entity edge,document edge<br>(1) intra-entity edge 同一个entity的mention<br>(2) inter-entity edge 一个句子内的不同entity的mention<br>(3) document edge 所有mention和document node连接<br>然后使用GCN得到mention的文档级表示，将每个节点的所有层的表示都concat，作为节点的最终表示</p><p>(2) EG (entity-level graph)实体级别图<br>用所有的mention的表示平均作为entity的表示<br>根据路径推理机制来推理实体对之间的关系，能够允许模型实现多跳关系推理<br>将相同entity的hMG中mention融合</p><p>模型分为4个部分:<br>(1) encoding module:<br>输入 word embedding,entity type,coreference type<br>通过encoding得到这一层的输出。<br>(2) mention-level graph aggregation module</p><p>(3) entity-level graph inference module<br>(4) classification module</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1.概述&quot;&gt;&lt;/a&gt;1.概述&lt;/h1&gt;&lt;p&gt;文档级关系抽取中的实体对通常贯穿于文档的多个句子中，和句子级的关系抽取相比需要更多的信息。&lt;/p&gt;
&lt;p&gt;文档级关系抽取任务</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Ubuntu之文件编码类型</title>
    <link href="http://example.com/2021/01/28/Ubuntu%E4%B9%8B%E6%96%87%E4%BB%B6%E7%BC%96%E7%A0%81%E7%B1%BB%E5%9E%8B/"/>
    <id>http://example.com/2021/01/28/Ubuntu%E4%B9%8B%E6%96%87%E4%BB%B6%E7%BC%96%E7%A0%81%E7%B1%BB%E5%9E%8B/</id>
    <published>2021-01-28T05:05:00.000Z</published>
    <updated>2021-01-28T13:38:53.320Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-概述"><a href="#0-概述" class="headerlink" title="0 概述"></a>0 概述</h1><p>在Ubuntu系统中，常常会发现中文的文档出现乱码的问题，这是由于文件编码问题所导致的。为此，本篇文档是关于文档的编码类型而编写。</p><h1 id="1-操作"><a href="#1-操作" class="headerlink" title="1 操作"></a>1 操作</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file -i filename</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;0-概述&quot;&gt;&lt;a href=&quot;#0-概述&quot; class=&quot;headerlink&quot; title=&quot;0 概述&quot;&gt;&lt;/a&gt;0 概述&lt;/h1&gt;&lt;p&gt;在Ubuntu系统中，常常会发现中文的文档出现乱码的问题，这是由于文件编码问题所导致的。为此，本篇文档是关于文档的编码类型而</summary>
      
    
    
    
    
    <category term="ubuntu" scheme="http://example.com/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>CRF详解</title>
    <link href="http://example.com/2020/12/26/CRF%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2020/12/26/CRF%E8%AF%A6%E8%A7%A3/</id>
    <published>2020-12-26T03:24:49.000Z</published>
    <updated>2020-12-26T05:40:10.011Z</updated>
    
    <content type="html"><![CDATA[<p>CRF详解由下面的部分组成<br>1.公式<br>1.1 log线性模型<br>1.2 MEMMs<br>1.3 CRFs<br>2.代码</p><h1 id="1-公式"><a href="#1-公式" class="headerlink" title="1.公式"></a>1.公式</h1><p>这里主要是关于模型的原理</p><h2 id="1-1-log线性模型"><a href="#1-1-log线性模型" class="headerlink" title="1.1 log线性模型"></a>1.1 log线性模型</h2><h2 id="1-2-MEMMs"><a href="#1-2-MEMMs" class="headerlink" title="1.2 MEMMs"></a>1.2 MEMMs</h2><h2 id="1-3-CRFs"><a href="#1-3-CRFs" class="headerlink" title="1.3 CRFs"></a>1.3 CRFs</h2><h1 id="2-代码"><a href="#2-代码" class="headerlink" title="2.代码"></a>2.代码</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;CRF详解由下面的部分组成&lt;br&gt;1.公式&lt;br&gt;1.1 log线性模型&lt;br&gt;1.2 MEMMs&lt;br&gt;1.3 CRFs&lt;br&gt;2.代码&lt;/p&gt;
&lt;h1 id=&quot;1-公式&quot;&gt;&lt;a href=&quot;#1-公式&quot; class=&quot;headerlink&quot; title=&quot;1.公式&quot;&gt;&lt;</summary>
      
    
    
    
    
    <category term="crf" scheme="http://example.com/tags/crf/"/>
    
  </entry>
  
  <entry>
    <title>Python中tornado使用说明</title>
    <link href="http://example.com/2020/12/25/Python%E4%B8%ADtornado%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"/>
    <id>http://example.com/2020/12/25/Python%E4%B8%ADtornado%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/</id>
    <published>2020-12-25T03:07:30.000Z</published>
    <updated>2021-01-11T07:23:36.742Z</updated>
    
    <content type="html"><![CDATA[<p>tornado是一个网络具有异步功能的网络库。样例:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import tornado.ioloop</span><br><span class="line">import tornado.web</span><br><span class="line"></span><br><span class="line">class MainHandler(tornado.web.RequestHandler):</span><br><span class="line">    def get(self):</span><br><span class="line">        self.write(<span class="string">&quot;Hello, world&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    application = tornado.web.Application([</span><br><span class="line">        (r<span class="string">&quot;/&quot;</span>, MainHandler),</span><br><span class="line">    ])</span><br><span class="line">    application.listen(8888)</span><br><span class="line">    tornado.ioloop.IOLoop.current().start()</span><br></pre></td></tr></table></figure><p>运行上面的程序之后，然后打开浏览器输入:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">localhost:8888</span><br></pre></td></tr></table></figure><h1 id="URL相关"><a href="#URL相关" class="headerlink" title="URL相关"></a>URL相关</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protocol :// hostname[:port] / path / [;parameters] [?query] <span class="comment"># fragment</span></span><br></pre></td></tr></table></figure><p>protocol 协议<br>hostname 主机名<br>port     端口号<br>path     路径<br>parameters 参数<br>query    查询<br>fragment 信息片段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.get_argument(&quot;text&quot;)</span><br><span class="line">localhost:12308&#x2F;spo_extract?text&#x3D;你好</span><br></pre></td></tr></table></figure><h1 id="Get和post"><a href="#Get和post" class="headerlink" title="Get和post"></a>Get和post</h1><p>都是向服务器提交数据，而且从服务器获取数据</p><p>1.区别:<br>get通过地址栏传输<br>post通过报文传输</p><p>2.传送长度:<br>get的参数有长度限制，受限于url长度<br>post没有限制</p><p>3.TCP数据包<br>GET产生一个<br>POST产生2个<br>对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；</p><p>而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。</p><h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><h2 id="端口冲突-Address-already-in-use-解决方法"><a href="#端口冲突-Address-already-in-use-解决方法" class="headerlink" title="端口冲突(Address already in use)解决方法"></a>端口冲突(Address already in use)解决方法</h2><ol><li><p>我们在后端开发的过程中往往会在没有正常关闭某个正在执行的脚本或者程序而是直接关闭了Terminal(终端)或是通过其他方式的异常关闭导致了之前的端口实际上仍未被释放，这时候倘若我门想要再使用这个端口，就会抛出 “error:[Errno 98] Address already in use” 这样的异常。</p></li><li><p>这时候我们只需要找到正在利用这个端口的进程，并得到这个进程的PID，杀死这个PID对应的这个进程，就能够有效释放被占用的端口，后续再使用的时候就不会再抛出端口已经被占用的异常信息。</p></li><li><p>找到被占用的指定端口号所对应的进程信息并呈现，xxx处填写对应要查找的端口号：<br>sudo lsof -i:xxx</p></li></ol><p>4.关闭这个进程,xxx为PID：<br>sudo kill xxx</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;tornado是一个网络具有异步功能的网络库。样例:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span cla</summary>
      
    
    
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="tornado" scheme="http://example.com/tags/tornado/"/>
    
  </entry>
  
  <entry>
    <title>RickandMorty</title>
    <link href="http://example.com/2020/12/25/RickandMorty/"/>
    <id>http://example.com/2020/12/25/RickandMorty/</id>
    <published>2020-12-25T01:50:41.000Z</published>
    <updated>2020-12-25T01:55:21.361Z</updated>
    
    <content type="html"><![CDATA[<p>Rick and Morty<br><img src="/2020/12/25/RickandMorty/RM.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Rick and Morty&lt;br&gt;&lt;img src=&quot;/2020/12/25/RickandMorty/RM.png&quot;&gt;&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>transformers使用教程</title>
    <link href="http://example.com/2020/12/25/transformers%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <id>http://example.com/2020/12/25/transformers%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</id>
    <published>2020-12-25T01:44:14.000Z</published>
    <updated>2020-12-25T02:33:09.836Z</updated>
    
    <content type="html"><![CDATA[<p>参考资料:<br>huggingface transformers git<br><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p><p>示例:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from transformers import pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># Allocate a pipeline for sentiment-analysis</span></span><br><span class="line">&gt;&gt;&gt; classifier = pipeline(<span class="string">&#x27;sentiment-analysis&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; classifier(<span class="string">&#x27;We are very happy to include pipeline into the transformers repository.&#x27;</span>)</span><br><span class="line">[&#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;POSITIVE&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: 0.9978193640708923&#125;]</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from transformers import pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># Allocate a pipeline for question-answering</span></span><br><span class="line">&gt;&gt;&gt; question_answerer = pipeline(<span class="string">&#x27;question-answering&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; question_answerer(&#123;</span><br><span class="line">...     <span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;What is the name of the repository ?&#x27;</span>,</span><br><span class="line">...     <span class="string">&#x27;context&#x27;</span>: <span class="string">&#x27;Pipeline have been included in the huggingface/transformers repository&#x27;</span></span><br><span class="line">... &#125;)</span><br><span class="line">&#123;<span class="string">&#x27;score&#x27;</span>: 0.5135612454720828, <span class="string">&#x27;start&#x27;</span>: 35, <span class="string">&#x27;end&#x27;</span>: 59, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;huggingface/transformers&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p>To download and use any of the pretrained models on your given task, you just need to use those three lines of codes (PyTorch version):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from transformers import AutoTokenizer, AutoModel</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line">&gt;&gt;&gt; model = AutoModel.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; inputs = tokenizer(<span class="string">&quot;Hello world!&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">&gt;&gt;&gt; outputs = model(**inputs)</span><br></pre></td></tr></table></figure><p>or for TensorFlow:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from transformers import AutoTokenizer, TFAutoModel</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line">&gt;&gt;&gt; model = TFAutoModel.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; inputs = tokenizer(<span class="string">&quot;Hello world!&quot;</span>, return_tensors=<span class="string">&quot;tf&quot;</span>)</span><br><span class="line">&gt;&gt;&gt; outputs = model(**inputs)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考资料:&lt;br&gt;huggingface transformers git&lt;br&gt;&lt;a href=&quot;https://github.com/huggingface/transformers&quot;&gt;https://github.com/huggingface/transformer</summary>
      
    
    
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="transformers" scheme="http://example.com/tags/transformers/"/>
    
  </entry>
  
  <entry>
    <title>GRU说明</title>
    <link href="http://example.com/2020/12/24/GRU%E8%AF%B4%E6%98%8E/"/>
    <id>http://example.com/2020/12/24/GRU%E8%AF%B4%E6%98%8E/</id>
    <published>2020-12-24T04:18:21.000Z</published>
    <updated>2020-12-25T01:33:25.439Z</updated>
    
    <content type="html"><![CDATA[<p>参考:<br><a href="https://zhuanlan.zhihu.com/p/32481747">https://zhuanlan.zhihu.com/p/32481747</a></p><p>GRU（Gate Recurrent Unit）是循环神经网络（Recurrent Neural Network, RNN）的一种。和LSTM（Long-Short Term Memory）一样，也是为了解决长期记忆和反向传播中的梯度等问题而提出来的。</p><p>GRU和LSTM在很多情况下实际表现上相差无几，那么为什么我们要使用新人GRU（2014年提出）而不是相对经受了更多考验的LSTM（1997提出）呢。</p><p>相比LSTM，使用GRU能够达到相当的效果，并且相比之下更容易进行训练，能够很大程度上提高训练效率，因此很多时候会更倾向于使用GRU。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考:&lt;br&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32481747&quot;&gt;https://zhuanlan.zhihu.com/p/32481747&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GRU（Gate Recurrent Unit）是循环神经网络（R</summary>
      
    
    
    
    
    <category term="gru" scheme="http://example.com/tags/gru/"/>
    
  </entry>
  
  <entry>
    <title>配置文件参考说明</title>
    <link href="http://example.com/2020/12/22/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8F%82%E8%80%83%E8%AF%B4%E6%98%8E/"/>
    <id>http://example.com/2020/12/22/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8F%82%E8%80%83%E8%AF%B4%E6%98%8E/</id>
    <published>2020-12-22T06:56:32.000Z</published>
    <updated>2020-12-22T07:29:41.360Z</updated>
    
    <content type="html"><![CDATA[<p>在很多情况下，我们需要将一些参数保存在程序的外面，也就是作为配置文件进行保存，或者，提前写好配置文件，从中读取必须的参数，方便实现。</p><p>但是有很多的可以作为配置文件:<br>YAML<br>JSON<br>好像没有注释<br>ini<br>XML</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在很多情况下，我们需要将一些参数保存在程序的外面，也就是作为配置文件进行保存，或者，提前写好配置文件，从中读取必须的参数，方便实现。&lt;/p&gt;
&lt;p&gt;但是有很多的可以作为配置文件:&lt;br&gt;YAML&lt;br&gt;JSON&lt;br&gt;好像没有注释&lt;br&gt;ini&lt;br&gt;XML&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Python中利用seqeval模块进行序列标注算法的模型评估</title>
    <link href="http://example.com/2020/12/21/Python%E4%B8%AD%E5%88%A9%E7%94%A8seqeval%E6%A8%A1%E5%9D%97%E8%BF%9B%E8%A1%8C%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E7%AE%97%E6%B3%95%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"/>
    <id>http://example.com/2020/12/21/Python%E4%B8%AD%E5%88%A9%E7%94%A8seqeval%E6%A8%A1%E5%9D%97%E8%BF%9B%E8%A1%8C%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E7%AE%97%E6%B3%95%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</id>
    <published>2020-12-21T07:40:01.000Z</published>
    <updated>2020-12-21T10:43:18.389Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-概述"><a href="#0-概述" class="headerlink" title="0. 概述"></a>0. 概述</h1><p>在NLP任务中，我们经常需要使用序列标注算法，为此，我们需要评估该模型在序列标注任务中的效果，这里使用了seqeval模块。</p><p>一般而言，序列标注算法的格式有BIO、IOBES、BMES等。</p><p>模型的评价指标有，一般只会注意英文，中文容易弄混:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">真实值\预测值   |Positive       |Negative       |</span><br><span class="line">Positive        |True Positive  |False Negative |</span><br><span class="line">Negative        |False Positive |True Negative  |</span><br></pre></td></tr></table></figure><p>Precision = TP/(TP+FP)<br>预测为正的样本中有多少预测对了</p><p>Recall = TP/(TP+FN)<br>真实为正的样本中有多少预测对了</p><p>Accuracy = (TP+TN)/(TP+TN+FP+FN)</p><p>F1 Score = 1/2(1/recall + 1/precision)<br>= 2Recall*Precision/(Recall+Precision)</p><h1 id="1-样例"><a href="#1-样例" class="headerlink" title="1.样例"></a>1.样例</h1><p>参考官网资料</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from seqeval.metrics import accuracy_score,classification_report,f1_score</span><br><span class="line"></span><br><span class="line">y_true = [[<span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;B-MISC&#x27;</span>, <span class="string">&#x27;I-MISC&#x27;</span>, <span class="string">&#x27;I-MISC&#x27;</span>, <span class="string">&#x27;O&#x27;</span>], [<span class="string">&#x27;B- PER&#x27;</span>, <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;O&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">y_pred = [[<span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;B-MISC&#x27;</span>, <span class="string">&#x27;I-MISC&#x27;</span>, <span class="string">&#x27;I-MISC&#x27;</span>, <span class="string">&#x27;I-MISC&#x27;</span>, <span class="string">&#x27;O&#x27;</span>],[<span class="string">&#x27;B-PER&#x27;</span>, <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;O&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f1_score(y_true, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_true, y_pred))</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;0-概述&quot;&gt;&lt;a href=&quot;#0-概述&quot; class=&quot;headerlink&quot; title=&quot;0. 概述&quot;&gt;&lt;/a&gt;0. 概述&lt;/h1&gt;&lt;p&gt;在NLP任务中，我们经常需要使用序列标注算法，为此，我们需要评估该模型在序列标注任务中的效果，这里使用了seqeval模</summary>
      
    
    
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="seqeval" scheme="http://example.com/tags/seqeval/"/>
    
  </entry>
  
  <entry>
    <title>Python之版本相争</title>
    <link href="http://example.com/2020/12/17/Python%E4%B9%8B%E7%89%88%E6%9C%AC%E7%9B%B8%E4%BA%89/"/>
    <id>http://example.com/2020/12/17/Python%E4%B9%8B%E7%89%88%E6%9C%AC%E7%9B%B8%E4%BA%89/</id>
    <published>2020-12-17T07:53:29.000Z</published>
    <updated>2020-12-17T07:57:25.883Z</updated>
    
    <content type="html"><![CDATA[<p>在Ubuntu 20 版本的时候，不支持直接下载python2的pip ,所以，有下面的解决方法</p><ol><li><p>Start by enabling the universe repository:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository universe</span><br></pre></td></tr></table></figure></li><li><p>Update the packages index and install Python 2:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install python2</span><br></pre></td></tr></table></figure></li><li><p>Use curl to download the get-pip.py script:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://bootstrap.pypa.io/get-pip.py --output get-pip.py</span><br></pre></td></tr></table></figure></li><li><p>Once the repository is enabled, run the script as sudo user with python2 to install pip :</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo python2 get-pip.py</span><br></pre></td></tr></table></figure></li><li><p>Verify the installation</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip2 --version</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在Ubuntu 20 版本的时候，不支持直接下载python2的pip ,所以，有下面的解决方法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Start by enabling the universe repository:&lt;/p&gt;
&lt;figure class=&quot;highlight </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>LSTM分析</title>
    <link href="http://example.com/2020/12/15/LSTM%E5%88%86%E6%9E%90/"/>
    <id>http://example.com/2020/12/15/LSTM%E5%88%86%E6%9E%90/</id>
    <published>2020-12-15T07:46:44.000Z</published>
    <updated>2020-12-16T08:51:31.093Z</updated>
    
    <content type="html"><![CDATA[<p>关于LSTM模型:<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/LSTM%E6%A8%A1%E5%9E%8B.png"><br>参考:<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><p>细胞状态是LSTM的核心，如下图所示。<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/%E7%BB%86%E8%83%9E%E7%8A%B6%E6%80%81.png"><br>细胞状态就像是传送带，在整个链条中一直延伸，只有一些小的线性作用，有利于信息不加改变地流动。</p><p>LSTM模型通过门结构调节，具有向细胞状态删除或者增加信息的能力。</p><p>有三个门结构，来保护控制细胞状态。</p><p>forget gate layer<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/forget_layer.png"><br>我们首先需要确定之前的信息需要忘记多少<br>取决于h_t-1和x_t,输出0到1之间的数字。<br>1表示完全保留之前的信息C_t-1,0表示完全忘记之前的信息</p><p>input gate layer<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/input_layer.png"><br>然后，我们需要决定当前细胞状态需要加入多少新的信息。<br>这里有两个部分，第一个是sigmoid函数，叫做输入门层，决定了我们更新的系数i。然后一个tanh函数建立了一个候选的数值Ct，在下一步中，我们将会将这两个合并去更新状态。</p><p>更新旧的状态Ct-1<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/update.png"><br>这样，看上面的公式就很简单，首先是对之前的状态乘以一个系数，忘记一些信息，然后增加当前的状态乘以一个系数，记住一些当前的信息。</p><p>最后，我们应该决定一个节点的输出结果了。这个就诶过取决于我们的细胞状态，但是是过滤后的版本。<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/output.png"></p><p>我们先使用sigmoid层得到的我们应该输出的东西，然后哦将细胞状态通过tanh得到系数，将两个相乘，得到当前的状态h_t</p><p>LSTM有多个变种，这里就跳过。</p><p>其中比较重要的是BiLSTM,就是两个方向的LSTM的输出状态拼接到一起:<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/BiLSTM.png"></p><p>最后补充一下，在写代码的时候，使用的torch.nn.LSTM的官方资料说明:<br><img src="/2020/12/15/LSTM%E5%88%86%E6%9E%90/torch_nn.png"></p><p>下面是参数的说明:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">input_size – The number of expected features <span class="keyword">in</span> the input x</span><br><span class="line"></span><br><span class="line">hidden_size – The number of features <span class="keyword">in</span> the hidden state h</span><br><span class="line"></span><br><span class="line">num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking <span class="keyword">in</span> outputs of the first LSTM and computing the final results. Default: 1</span><br><span class="line"></span><br><span class="line">bias – If False, <span class="keyword">then</span> the layer does not use bias weights b_ih and b_hh. Default: True</span><br><span class="line"></span><br><span class="line">batch_first – If True, <span class="keyword">then</span> the input and output tensors are provided as (batch, seq, feature). Default: False</span><br><span class="line"></span><br><span class="line">dropout – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0</span><br><span class="line"></span><br><span class="line">bidirectional – If True, becomes a bidirectional LSTM. Default: False</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;关于LSTM模型:&lt;br&gt;&lt;img src=&quot;/2020/12/15/LSTM%E5%88%86%E6%9E%90/LSTM%E6%A8%A1%E5%9E%8B.png&quot;&gt;&lt;br&gt;参考:&lt;a href=&quot;https://colah.github.io/posts/2015-</summary>
      
    
    
    
    
    <category term="lstm" scheme="http://example.com/tags/lstm/"/>
    
  </entry>
  
  <entry>
    <title>spo抽取知识图谱</title>
    <link href="http://example.com/2020/12/11/spo%E6%8A%BD%E5%8F%96%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    <id>http://example.com/2020/12/11/spo%E6%8A%BD%E5%8F%96%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/</id>
    <published>2020-12-11T11:07:43.000Z</published>
    <updated>2020-12-11T11:33:04.815Z</updated>
    
    <content type="html"><![CDATA[<p>参考:<br><a href="https://github.com/percent4/spo_extract_platform">https://github.com/percent4/spo_extract_platform</a></p><p>知识图谱的构建由两个部分构成:<br>1.SPO三元组抽取:序列标注算法(ALBERT+BiLSTM+CRF)<br>SPO:Subject(主语) Predicate(谓语) Object(宾语)<br>sequence_labeling F1:81%</p><p>2.关系抽取:文本二分类(ALBERT+BiGRU+ATT)<br>text_classification F1:96%</p><p>提取无结构文本的应用在extract_example<br>下面会对这两个部分分别做完整的介绍:</p><h1 id="1-SPO三元组"><a href="#1-SPO三元组" class="headerlink" title="1.SPO三元组"></a>1.SPO三元组</h1><p><img src="/2020/12/11/spo%E6%8A%BD%E5%8F%96%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/ALBERT_BiLSTM_CRF.png"><br>上面是模型的框架</p><h2 id="1-ALBERT层"><a href="#1-ALBERT层" class="headerlink" title="1.ALBERT层"></a>1.ALBERT层</h2><p>albert是以单个汉字作为输入的(本次配置最大为128个，短句做padding)，两边分别加上开始标识CLS和结束标识SEP，输出的是每个输入word的embedding。在该框架中其实主要就是利用了预训练模型albert的词嵌入功能，在此基础上fine-tuning其后面的连接参数，也就是albert内部的训练参数不参与训练。</p><h2 id="2-BiLSTM层"><a href="#2-BiLSTM层" class="headerlink" title="2.BiLSTM层"></a>2.BiLSTM层</h2><p>该层的输入是albert的embedding输出，一般中间会加个project_layer，保证其输出是[batch_szie,num_steps, num_tags]。batch_size为模型当中batch的大小，num_steps为输入句子的长度，本次配置为最大128，num_tags为序列标注的个数，如图中的序列标注一共是5个，也就是会输出每个词在5个tag上的分数，由于没有做softmax归一化，所以不能称之为概率值。</p><h2 id="3-CRF层"><a href="#3-CRF层" class="headerlink" title="3.CRF层"></a>3.CRF层</h2><p>如果没有CRF层，直接按BiLSTM每个词在5个tag的最大分数作为输出的话，可能会出现【B-Person，O，I-Person，O，I-Location】这种序列，显然不符合实际情况。CRF层可以加入一些约束条件，从而保证最终预测结果是有效的。</p><p>例如：<br>句子的开头应该是“B-”或“O”，而不是“I-”。</p><h1 id="2-关系抽取"><a href="#2-关系抽取" class="headerlink" title="2.关系抽取"></a>2.关系抽取</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考:&lt;br&gt;&lt;a href=&quot;https://github.com/percent4/spo_extract_platform&quot;&gt;https://github.com/percent4/spo_extract_platform&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;知识图谱的构建由两个部</summary>
      
    
    
    
    
    <category term="知识图谱" scheme="http://example.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="http://example.com/2020/12/10/test/"/>
    <id>http://example.com/2020/12/10/test/</id>
    <published>2020-12-10T05:35:43.000Z</published>
    <updated>2020-12-10T05:38:27.776Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2020/12/10/test/cat.jpeg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/2020/12/10/test/cat.jpeg&quot;&gt;&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Ubuntu之GPU运算不归路</title>
    <link href="http://example.com/2020/12/01/Ubuntu%E4%B9%8BGPU%E8%BF%90%E7%AE%97%E4%B8%8D%E5%BD%92%E8%B7%AF/"/>
    <id>http://example.com/2020/12/01/Ubuntu%E4%B9%8BGPU%E8%BF%90%E7%AE%97%E4%B8%8D%E5%BD%92%E8%B7%AF/</id>
    <published>2020-12-01T08:12:52.000Z</published>
    <updated>2020-12-01T08:22:05.332Z</updated>
    
    <content type="html"><![CDATA[<p>之前，本人尝试在Ubuntu系统上进行GPU运算，装GPU驱动等等。<br>以失败告终，最后，在命令行模式下转移了自己的部分资料，然后重装了系统。<br>面对这个惨痛的教训，我怎么能够忍气吞声，开始筹备第二次GPU远征。</p><p>这次，我先保存资料，以供后人借鉴。</p><p>首先，检查电脑上的GPU信息:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i nvidia <span class="comment">#可以查询所有的nvidia显卡</span></span><br><span class="line"></span><br><span class="line">lspci -v -s [显卡编号] <span class="comment">#可以查询显卡的具体属性</span></span><br><span class="line"></span><br><span class="line">nvidia-smi <span class="comment">#可以查看显卡的显存利用率，特别注意，这个需要下载驱动，没有下载驱动的，请小心，上次我就下载驱动之后就出问题了</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;之前，本人尝试在Ubuntu系统上进行GPU运算，装GPU驱动等等。&lt;br&gt;以失败告终，最后，在命令行模式下转移了自己的部分资料，然后重装了系统。&lt;br&gt;面对这个惨痛的教训，我怎么能够忍气吞声，开始筹备第二次GPU远征。&lt;/p&gt;
&lt;p&gt;这次，我先保存资料，以供后人借鉴。&lt;/</summary>
      
    
    
    
    
    <category term="ubuntu" scheme="http://example.com/tags/ubuntu/"/>
    
    <category term="gpu" scheme="http://example.com/tags/gpu/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch使用说明</title>
    <link href="http://example.com/2020/11/27/PyTorch%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"/>
    <id>http://example.com/2020/11/27/PyTorch%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/</id>
    <published>2020-11-27T11:25:15.000Z</published>
    <updated>2020-12-29T00:43:45.724Z</updated>
    
    <content type="html"><![CDATA[<p>参考资料:<br><a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html</a></p><p>第一部分 tensor + operator</p><p>第二部分 autograd<br>torch.Tnesor是包中的核心类，<br>.requires_grad = True，那么会自动跟踪所有运算，<br>.backward() 当你结束运算调用这个函数，就会自动计算梯度。<br>.grad 梯度会计算放到这里</p><p>.detach() 可以停止跟踪<br>with torch.no_grad(): 停止跟踪<br>上面的在评估模型的时候非常有用</p><p>Function类也是一个很重要的类别。<br>.grad_fn 是一个tensor被一个函数建立</p><p>随机数初始化:<br>在神经网络中，参数默认是进行随机初始化的，不同的初始化参数往往会导致不同的结果，当得到比较好的结果的时候，我们希望结果可以复现，在torch中，通过设置随机数种子可以达到这个目的:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def set_seed(seed):</span><br><span class="line">    torch.manual_seed(seed)  </span><br><span class="line">    <span class="comment"># cpu 为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class="line">    torch.cuda.manual_seed(seed)  </span><br><span class="line">    <span class="comment"># gpu 为当前GPU设置随机种子</span></span><br><span class="line">    torch.backends.cudnn.deterministic = True  </span><br><span class="line">    <span class="comment"># cudnn 每次返回的卷积算法都是确定的，即默认算法</span></span><br><span class="line">    np.random.seed(seed)  </span><br><span class="line">    <span class="comment"># numpy</span></span><br><span class="line">    random.seed(seed)  </span><br><span class="line">    <span class="comment"># random and transforms</span></span><br></pre></td></tr></table></figure><p>在程序的入口处设置随机数种子</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set_seed(1)</span><br></pre></td></tr></table></figure><p>1.当我们训练了一个模型之后，需要将训练得到的模型进行保存。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PATH = <span class="string">&#x27;./cifar_net.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(),PATH)</span><br></pre></td></tr></table></figure><p>2.测试网络</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新加载保存的模型</span></span><br><span class="line">net = Net()</span><br><span class="line">net.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure><p>保存模型的方式不同。会导致模型有可能不同</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">torch.save(net,<span class="string">&#x27;./model.pth&#x27;</span>)</span><br><span class="line">torch.save(net.state_dict(),<span class="string">&#x27;./model-dict.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">net=torch.load(<span class="string">&#x27;./model.pth&#x27;</span>)</span><br><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;./model-dict.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了加载之后相同，需要指定eval模式</span></span><br><span class="line"><span class="comment">#保存</span></span><br><span class="line">net=net.eval()</span><br><span class="line">torch.save(net,<span class="string">&#x27;./model.pth&#x27;</span>)</span><br><span class="line">torch.save(net.state_dict(),<span class="string">&#x27;./model-dict.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载</span></span><br><span class="line">net_load1=torch.load(<span class="string">&#x27;./model.pth&#x27;</span>)</span><br><span class="line">net_load1=net_load1.eval()</span><br><span class="line"></span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">net_load2.load_state_dict(torch.load(<span class="string">&#x27;./model-dict.pth&#x27;</span>))</span><br><span class="line">net_load2=net_load2.eval()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>model.state_dict()是浅拷贝，返回的参数依然会随着网络的训练而变化，需要deepcopy或者拷贝到硬盘中。</p><p>在state_dict中有下面四个内容:<br>1._paramters<br>nn.parameter.Paramter，也就是组成Module的参数。例如一个nn.Linear通常由weight和bias参数组成。它的特点是默认requires_grad=True,也就是说训练过程中需要反向传播的<br>2._buffers<br>不需要参与反向传播的参数<br>3._modules<br>torch.nn.Module类，你定义的所有网络结构都必须继承这个类。<br>4._state_dict_hooks<br>最后一种就是在读取state_dict时希望执行的操作，一般为空，所以不做考虑。</p><p>关于NLLLoss的代码说明:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">torch.manual_seed(2019)</span><br><span class="line"></span><br><span class="line">output = torch.randn(1, 3)  <span class="comment"># 网络输出</span></span><br><span class="line">target = torch.ones(1, dtype=torch.long).random_(3)  <span class="comment"># 真实标签</span></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接调用</span></span><br><span class="line">loss = F.nll_loss(output, target)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化类</span></span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><p>计算公式：loss(input, class) = -input[class]<br>公式理解：input = [-0.1187, 0.2110, 0.7463]，target = [1]，那么 loss = -0.2110<br>个人理解：感觉像是把 target 转换成 one-hot 编码，然后与 input 点乘得到的结果</p><p>如果 input 维度为 M x N，那么 loss 默认取 M 个 loss 的平均值，reduction=’none’ 表示显示全部 loss</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">torch.manual_seed(2019)</span><br><span class="line"></span><br><span class="line">output = torch.randn(2, 3)  <span class="comment"># 网路输出</span></span><br><span class="line">target = torch.ones(2, dtype=torch.long).random_(3)  <span class="comment"># 真实标签</span></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接调用</span></span><br><span class="line">loss = F.nll_loss(output, target)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化类</span></span><br><span class="line">criterion = nn.NLLLoss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">tensor([[-0.1187,  0.2110,  0.7463],</span></span><br><span class="line"><span class="string">        [-0.6136, -0.1186,  1.5565]])</span></span><br><span class="line"><span class="string">tensor([2, 0])</span></span><br><span class="line"><span class="string">tensor(-0.0664)</span></span><br><span class="line"><span class="string">tensor([-0.7463,  0.6136])</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>那么CrossEntropyLoss和NLLLoss区别在于<br>CrossEntropyLoss = Softmax+Log+NLLLoss</p><p>还有<br>ignore_index 就是计算的时候忽略的标签的数值</p><h1 id="梯度计算以及backward方法"><a href="#梯度计算以及backward方法" class="headerlink" title="梯度计算以及backward方法"></a>梯度计算以及backward方法</h1><p>tensor在torch中是一个n维数组，我们通过指定参数requires_grad = True来建立一个反向传播图，从而可以计算梯度。被称之为动态计算图Dynamic Computation Graph。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># solution 1</span></span><br><span class="line">x = torch.randn(2,2,requires_grad=True)</span><br><span class="line"></span><br><span class="line"><span class="comment"># solution 2</span></span><br><span class="line">x = torch.autograd.Variable(torch.Tensor([2,3]),requires_grad=True)</span><br><span class="line"></span><br><span class="line"><span class="comment"># solution 3</span></span><br><span class="line">x = torch.tensor([2,3],requires_grad=True,dtype=torch.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># solution 4</span></span><br><span class="line">x = np.array([1,2,3],dtype=np.float64)</span><br><span class="line">x = torch.from_numpy(x)</span><br><span class="line">x.requires_grad = True</span><br><span class="line"><span class="comment"># or x.requires_grad(Ture)</span></span><br></pre></td></tr></table></figure><p>attention:<br>1.只有浮点型数据才有梯度，</p><p>tensor是PyTorch中的组建，Variable是对tensor的封装，操作和tensor一样，但是每个variable都有三个属性，包含了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.data 数据</span><br><span class="line">.grad 梯度</span><br><span class="line">.grad_fn 变量的得到方式</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考资料:&lt;br&gt;&lt;a href=&quot;https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html&quot;&gt;https://pytorch.org/tutorials/beginner/deep_lear</summary>
      
    
    
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="torch" scheme="http://example.com/tags/torch/"/>
    
  </entry>
  
  <entry>
    <title>LaTeX使用说明</title>
    <link href="http://example.com/2020/11/26/LaTeX%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"/>
    <id>http://example.com/2020/11/26/LaTeX%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/</id>
    <published>2020-11-26T15:36:25.000Z</published>
    <updated>2020-12-26T15:17:07.376Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-环境配置"><a href="#0-环境配置" class="headerlink" title="0.环境配置"></a>0.环境配置</h1><p>下载</p><h1 id="1-使用说明"><a href="#1-使用说明" class="headerlink" title="1.使用说明"></a>1.使用说明</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">% 注释</span><br><span class="line">\\ 换行</span><br><span class="line">\<span class="keyword">in</span> 属于</span><br><span class="line">\notin  不属于</span><br></pre></td></tr></table></figure><p><img src="/2020/11/26/LaTeX%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/alpha.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;0-环境配置&quot;&gt;&lt;a href=&quot;#0-环境配置&quot; class=&quot;headerlink&quot; title=&quot;0.环境配置&quot;&gt;&lt;/a&gt;0.环境配置&lt;/h1&gt;&lt;p&gt;下载&lt;/p&gt;
&lt;h1 id=&quot;1-使用说明&quot;&gt;&lt;a href=&quot;#1-使用说明&quot; class=&quot;header</summary>
      
    
    
    
    
    <category term="latex" scheme="http://example.com/tags/latex/"/>
    
  </entry>
  
</feed>
